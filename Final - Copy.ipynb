{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dbb910-7642-465f-9b48-2af7a1884cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  8 11:51:53 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.01              Driver Version: 546.01       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    On  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   57C    P8               2W /  55W |     12MiB /  8188MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        23      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a681ca-d8f0-4b6c-b170-b3756508cde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Mon_Oct_24_19:12:58_PDT_2022\n",
      "Cuda compilation tools, release 12.0, V12.0.76\n",
      "Build cuda_12.0.r12.0/compiler.31968024_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93abaed0-76f0-4239-b80a-156183849070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom numba import cuda\\ncuda.get_current_device().reset()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from numba import cuda\n",
    "cuda.get_current_device().reset()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd7f8aa-035e-48e7-98d2-e75551be5faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:51:55.504812: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-08 11:51:55.537812: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-08 11:51:55.537845: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-08 11:51:55.537869: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-08 11:51:55.565633: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b54739b-af94-413c-aa1b-27d5039bd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aa210d-5e3c-4dcd-bff3-5130a0b9cb31",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e8ce5d-0845-428e-b030-9af626ff20f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_fasion_mnist = tfds.as_numpy(tfds.load(\"fashion_mnist\", split=\"train\", batch_size=-1))\\nX_train, y_train   = train_fasion_mnist[\"image\"], train_fasion_mnist[\"label\"]\\n\\n# Test\\ntest_fasion_mnist  = tfds.as_numpy(tfds.load(\"fashion_mnist\", split=\"test\", batch_size=-1))\\nX_test, y_test     = test_fasion_mnist[\"image\"], test_fasion_mnist[\"label\"]\\n\\nprint(\"Train Samples:\", len(X_train))\\nprint(\"Test Samples:\",  len(X_test))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_fasion_mnist = tfds.as_numpy(tfds.load(\"fashion_mnist\", split=\"train\", batch_size=-1))\n",
    "X_train, y_train   = train_fasion_mnist[\"image\"], train_fasion_mnist[\"label\"]\n",
    "\n",
    "# Test\n",
    "test_fasion_mnist  = tfds.as_numpy(tfds.load(\"fashion_mnist\", split=\"test\", batch_size=-1))\n",
    "X_test, y_test     = test_fasion_mnist[\"image\"], test_fasion_mnist[\"label\"]\n",
    "\n",
    "print(\"Train Samples:\", len(X_train))\n",
    "print(\"Test Samples:\",  len(X_test))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af1024e-585e-4c2e-866f-a02fb62bbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a7203a-1fcc-439b-b640-c5ba0f6c28ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b96b4e-63f6-4ec0-9ba7-29ae0f96be74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489ba81a-dd7c-448e-85b9-393458374988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "564d0487-30d0-4df3-8133-9e04e4c67523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d941bc5-8133-4e5d-b868-6d9e5acc7959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 60000\n",
      "Test Samples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Samples:\", len(X_train))\n",
    "print(\"Test Samples:\",  len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d99f473c-b8bf-4ff2-9cef-f1af40fb2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Dimension of images #\n",
    "#######################\n",
    "img_width  = 28\n",
    "img_height = 28\n",
    "channels   = 1\n",
    "\n",
    "image_shape = (img_height, img_width, channels)\n",
    "\n",
    "######################\n",
    "# Parms for learning #\n",
    "######################\n",
    "batch_size = 250\n",
    "num_epochs = 80\n",
    "iterations = 5          # number of iterations\n",
    "nb_augmentation = 2     # defines the number of additional augmentations of one image\n",
    "\n",
    "####################\n",
    "#       Data       #\n",
    "####################\n",
    "fashion_classes     = {0: 'T-shirt/top',\n",
    "                       1: 'Trouser',\n",
    "                       2: 'Pullover',\n",
    "                       3: 'Dress',\n",
    "                       4: 'Coat',\n",
    "                       5: 'Sandal',\n",
    "                       6: 'Shirt',\n",
    "                       7: 'Sneaker',\n",
    "                       8: 'Bag',\n",
    "                       9: 'Ankle boot'}\n",
    "\n",
    "mnist_classes       = [i for i in range(10)]\n",
    "num_classes         = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9522f7-4732-46ea-9e9a-223b9fe238bf",
   "metadata": {},
   "source": [
    "## Plot Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7f0c162-5136-4574-9120-d556a46c91cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: T-shirt/top\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(X_train))\n",
    "plt.imshow(np.squeeze(X_train[idx]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Target:\", fashion_classes[y_train[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9bf654-c163-4636-b9c2-c8b41a4ed4b6",
   "metadata": {},
   "source": [
    "## Data Augmentation and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69405735-f1aa-4fec-a5cc-7e9f3154d99b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Preprocessing completed: 180000 samples\n",
      "\n",
      "*Preprocessing completed: 10000 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_shaped, y_train_shaped = utils.preprocess_data(\n",
    "    X_train, y_train,\n",
    "    use_augmentation=True,\n",
    "    nb_of_augmentation=nb_augmentation\n",
    ")\n",
    "\n",
    "X_test_shaped, y_test_shaped = utils.preprocess_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a3b67-c768-4eab-880a-c94fce6f47fc",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72040490-035a-40bb-971d-46f6f4ccb9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:52:11.085653: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-08 11:52:11.095738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-08 11:52:11.095779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-08 11:52:11.097724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-08 11:52:11.097773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-08 11:52:11.097786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-08 11:52:11.497109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-08 11:52:11.497177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-08 11:52:11.497184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-08 11:52:11.497232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-08 11:52:11.497253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5578 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:52:21.070895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-08 11:52:22.769120: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0605f221b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-08 11:52:22.769150: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2023-11-08 11:52:22.773469: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-08 11:52:22.853374: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575/576 [============================>.] - ETA: 0s - loss: 0.7699 - accuracy: 0.7456\n",
      "Epoch 1: val_loss improved from inf to 0.38941, saving model to fashion_mnist_ResNet50-0.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srijan/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 53s 56ms/step - loss: 0.7692 - accuracy: 0.7458 - val_loss: 0.3894 - val_accuracy: 0.8571\n",
      "Epoch 2/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.8727\n",
      "Epoch 2: val_loss improved from 0.38941 to 0.32157, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 31s 54ms/step - loss: 0.3443 - accuracy: 0.8727 - val_loss: 0.3216 - val_accuracy: 0.8800\n",
      "Epoch 3/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2921 - accuracy: 0.8915\n",
      "Epoch 3: val_loss improved from 0.32157 to 0.27222, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 31s 55ms/step - loss: 0.2921 - accuracy: 0.8915 - val_loss: 0.2722 - val_accuracy: 0.8974\n",
      "Epoch 4/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9008\n",
      "Epoch 4: val_loss did not improve from 0.27222\n",
      "576/576 [==============================] - 31s 53ms/step - loss: 0.2659 - accuracy: 0.9007 - val_loss: 0.2724 - val_accuracy: 0.8989\n",
      "Epoch 5/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.9098\n",
      "Epoch 5: val_loss improved from 0.27222 to 0.24496, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 31s 53ms/step - loss: 0.2448 - accuracy: 0.9098 - val_loss: 0.2450 - val_accuracy: 0.9074\n",
      "Epoch 6/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9152\n",
      "Epoch 6: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 50ms/step - loss: 0.2289 - accuracy: 0.9152 - val_loss: 0.2613 - val_accuracy: 0.9033\n",
      "Epoch 7/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.8675 - accuracy: 0.7443\n",
      "Epoch 7: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 50ms/step - loss: 0.8675 - accuracy: 0.7443 - val_loss: 0.5313 - val_accuracy: 0.7986\n",
      "Epoch 8/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.8251\n",
      "Epoch 8: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 50ms/step - loss: 0.4733 - accuracy: 0.8251 - val_loss: 0.4336 - val_accuracy: 0.8387\n",
      "Epoch 9/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.8538\n",
      "Epoch 9: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 51ms/step - loss: 0.3959 - accuracy: 0.8538 - val_loss: 0.3787 - val_accuracy: 0.8577\n",
      "Epoch 10/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.3537 - accuracy: 0.8689\n",
      "Epoch 10: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 51ms/step - loss: 0.3537 - accuracy: 0.8689 - val_loss: 0.3409 - val_accuracy: 0.8721\n",
      "Epoch 11/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.3224 - accuracy: 0.8810\n",
      "Epoch 11: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 51ms/step - loss: 0.3224 - accuracy: 0.8810 - val_loss: 0.3211 - val_accuracy: 0.8794\n",
      "Epoch 12/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3018 - accuracy: 0.8877\n",
      "Epoch 12: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 51ms/step - loss: 0.3018 - accuracy: 0.8877 - val_loss: 0.3150 - val_accuracy: 0.8836\n",
      "Epoch 13/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.2832 - accuracy: 0.8951\n",
      "Epoch 13: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 51ms/step - loss: 0.2831 - accuracy: 0.8951 - val_loss: 0.2909 - val_accuracy: 0.8925\n",
      "Epoch 14/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.9000\n",
      "Epoch 14: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 30s 51ms/step - loss: 0.2691 - accuracy: 0.9000 - val_loss: 0.2775 - val_accuracy: 0.8952\n",
      "Epoch 15/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.2582 - accuracy: 0.9034\n",
      "Epoch 15: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 51ms/step - loss: 0.2582 - accuracy: 0.9034 - val_loss: 0.2831 - val_accuracy: 0.8941\n",
      "Epoch 16/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.2453 - accuracy: 0.9091\n",
      "Epoch 16: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 51ms/step - loss: 0.2452 - accuracy: 0.9091 - val_loss: 0.2602 - val_accuracy: 0.9051\n",
      "Epoch 17/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.9134\n",
      "Epoch 17: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 29s 51ms/step - loss: 0.2336 - accuracy: 0.9134 - val_loss: 0.2530 - val_accuracy: 0.9055\n",
      "Epoch 18/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.9166\n",
      "Epoch 18: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 30s 51ms/step - loss: 0.2250 - accuracy: 0.9166 - val_loss: 0.2522 - val_accuracy: 0.9071\n",
      "Epoch 19/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9193\n",
      "Epoch 19: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 30s 52ms/step - loss: 0.2166 - accuracy: 0.9192 - val_loss: 0.2550 - val_accuracy: 0.9038\n",
      "Epoch 20/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9222\n",
      "Epoch 20: val_loss did not improve from 0.24496\n",
      "576/576 [==============================] - 30s 51ms/step - loss: 0.2072 - accuracy: 0.9222 - val_loss: 0.2498 - val_accuracy: 0.9099\n",
      "Epoch 21/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.1984 - accuracy: 0.9263\n",
      "Epoch 21: val_loss improved from 0.24496 to 0.24036, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 32s 56ms/step - loss: 0.1983 - accuracy: 0.9263 - val_loss: 0.2404 - val_accuracy: 0.9105\n",
      "Epoch 22/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1916 - accuracy: 0.9286\n",
      "Epoch 22: val_loss improved from 0.24036 to 0.23981, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 32s 56ms/step - loss: 0.1916 - accuracy: 0.9286 - val_loss: 0.2398 - val_accuracy: 0.9145\n",
      "Epoch 23/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.9320\n",
      "Epoch 23: val_loss improved from 0.23981 to 0.22353, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 31s 54ms/step - loss: 0.1815 - accuracy: 0.9320 - val_loss: 0.2235 - val_accuracy: 0.9178\n",
      "Epoch 24/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.1721 - accuracy: 0.9363\n",
      "Epoch 24: val_loss improved from 0.22353 to 0.21655, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 34s 60ms/step - loss: 0.1720 - accuracy: 0.9363 - val_loss: 0.2166 - val_accuracy: 0.9193\n",
      "Epoch 25/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9386\n",
      "Epoch 25: val_loss improved from 0.21655 to 0.20898, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 33s 57ms/step - loss: 0.1652 - accuracy: 0.9386 - val_loss: 0.2090 - val_accuracy: 0.9237\n",
      "Epoch 26/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.9409\n",
      "Epoch 26: val_loss did not improve from 0.20898\n",
      "576/576 [==============================] - 31s 54ms/step - loss: 0.1574 - accuracy: 0.9409 - val_loss: 0.2154 - val_accuracy: 0.9221\n",
      "Epoch 27/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9458\n",
      "Epoch 27: val_loss did not improve from 0.20898\n",
      "576/576 [==============================] - 31s 54ms/step - loss: 0.1443 - accuracy: 0.9458 - val_loss: 0.2169 - val_accuracy: 0.9215\n",
      "Epoch 28/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9481\n",
      "Epoch 28: val_loss improved from 0.20898 to 0.20244, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 34s 59ms/step - loss: 0.1395 - accuracy: 0.9481 - val_loss: 0.2024 - val_accuracy: 0.9264\n",
      "Epoch 29/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 0.9507\n",
      "Epoch 29: val_loss did not improve from 0.20244\n",
      "576/576 [==============================] - 32s 56ms/step - loss: 0.1307 - accuracy: 0.9507 - val_loss: 0.2073 - val_accuracy: 0.9275\n",
      "Epoch 30/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9545\n",
      "Epoch 30: val_loss did not improve from 0.20244\n",
      "576/576 [==============================] - 32s 55ms/step - loss: 0.1209 - accuracy: 0.9545 - val_loss: 0.2076 - val_accuracy: 0.9280\n",
      "Epoch 31/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.9301\n",
      "Epoch 31: val_loss did not improve from 0.20244\n",
      "576/576 [==============================] - 31s 54ms/step - loss: 0.1892 - accuracy: 0.9301 - val_loss: 0.4099 - val_accuracy: 0.8908\n",
      "Epoch 32/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9178\n",
      "Epoch 32: val_loss did not improve from 0.20244\n",
      "576/576 [==============================] - 30s 52ms/step - loss: 0.2176 - accuracy: 0.9177 - val_loss: 0.2164 - val_accuracy: 0.9204\n",
      "Epoch 33/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.1557 - accuracy: 0.9413\n",
      "Epoch 33: val_loss did not improve from 0.20244\n",
      "576/576 [==============================] - 30s 51ms/step - loss: 0.1558 - accuracy: 0.9412 - val_loss: 0.2089 - val_accuracy: 0.9253\n",
      "Epoch 34/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9512\n",
      "Epoch 34: val_loss improved from 0.20244 to 0.20227, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 31s 54ms/step - loss: 0.1283 - accuracy: 0.9512 - val_loss: 0.2023 - val_accuracy: 0.9284\n",
      "Epoch 35/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9581\n",
      "Epoch 35: val_loss did not improve from 0.20227\n",
      "576/576 [==============================] - 30s 52ms/step - loss: 0.1115 - accuracy: 0.9581 - val_loss: 0.2034 - val_accuracy: 0.9311\n",
      "Epoch 36/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9618\n",
      "Epoch 36: val_loss improved from 0.20227 to 0.19412, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 31s 55ms/step - loss: 0.1006 - accuracy: 0.9618 - val_loss: 0.1941 - val_accuracy: 0.9341\n",
      "Epoch 37/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.0928 - accuracy: 0.9650\n",
      "Epoch 37: val_loss did not improve from 0.19412\n",
      "576/576 [==============================] - 30s 52ms/step - loss: 0.0928 - accuracy: 0.9650 - val_loss: 0.1969 - val_accuracy: 0.9348\n",
      "Epoch 38/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9667\n",
      "Epoch 38: val_loss did not improve from 0.19412\n",
      "576/576 [==============================] - 30s 52ms/step - loss: 0.0878 - accuracy: 0.9667 - val_loss: 0.2043 - val_accuracy: 0.9357\n",
      "Epoch 39/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9696\n",
      "Epoch 39: val_loss improved from 0.19412 to 0.19286, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 31s 55ms/step - loss: 0.0815 - accuracy: 0.9696 - val_loss: 0.1929 - val_accuracy: 0.9381\n",
      "Epoch 40/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.0784 - accuracy: 0.9708\n",
      "Epoch 40: val_loss improved from 0.19286 to 0.18898, saving model to fashion_mnist_ResNet50-0.hdf5\n",
      "576/576 [==============================] - 32s 55ms/step - loss: 0.0784 - accuracy: 0.9709 - val_loss: 0.1890 - val_accuracy: 0.9388\n",
      "Epoch 41/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9735\n",
      "Epoch 41: val_loss did not improve from 0.18898\n",
      "576/576 [==============================] - 30s 52ms/step - loss: 0.0708 - accuracy: 0.9735 - val_loss: 0.2085 - val_accuracy: 0.9366\n",
      "Epoch 42/80\n",
      "575/576 [============================>.] - ETA: 0s - loss: 0.0707 - accuracy: 0.9739\n",
      "Epoch 42: val_loss did not improve from 0.18898\n",
      "576/576 [==============================] - 30s 52ms/step - loss: 0.0707 - accuracy: 0.9739 - val_loss: 0.1955 - val_accuracy: 0.9400\n",
      "Epoch 43/80\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9755\n",
      "Epoch 43: val_loss did not improve from 0.18898\n",
      "576/576 [==============================] - 30s 52ms/step - loss: 0.0655 - accuracy: 0.9755 - val_loss: 0.2009 - val_accuracy: 0.9403\n",
      "Epoch 44/80\n",
      "315/576 [===============>..............] - ETA: 14s - loss: 0.0591 - accuracy: 0.9786"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for i in range(0,iterations):\n",
    "    print('Running iteration: %i' % i)\n",
    "\n",
    "    # Saving the best checkpoint for each iteration\n",
    "    filepath = \"fashion_mnist_ResNet50-%i.hdf5\" % i\n",
    "\n",
    "    X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train_shaped, y_train_shaped,\n",
    "                                                          test_size=0.2, random_state=42)\n",
    "\n",
    "    cnn = models.create_resnet50(input_shape = (img_height, img_width, channels), classes = num_classes)\n",
    "    tick = time.perf_counter()\n",
    "    history = cnn.fit(\n",
    "        X_train_, y_train_,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val_, y_val_),\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.05, patience=10, start_from_epoch=50, verbose=1, mode='max'),  \n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        ]\n",
    "    )\n",
    "    tock = time.perf_counter()\n",
    "    histories.append(history.history)\n",
    "    print(f\"Time to train model {i+1}: {(tock-tick)/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85a693-b8eb-4b7a-b586-218cb8768548",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f17b16-35ae-47a4-b08b-0ddfe4347c60",
   "metadata": {},
   "source": [
    "## Training scores for loss and accuracy for all checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87de8af-1e1a-4ddb-adab-383ea91d6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training: \\t%0.8f loss / %0.8f acc'   % (utils.get_avg(histories,'loss'), utils.get_avg(histories,'accuracy')))\n",
    "print('Validation: \\t%0.8f loss / %0.8f acc' % (utils.get_avg(histories,'val_loss'), utils.get_avg(histories,'val_accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92eed13-1af6-4125-81c4-55a0fc1cb5a9",
   "metadata": {},
   "source": [
    "## Loss / accuracy of all models on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad33076-ef2a-4a74-a81c-d9a433b19b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "test_accs = []\n",
    "\n",
    "for i in range(0,iterations):\n",
    "    cnn_ = tf.keras.models.load_model(\"fashion_mnist_ResNet50-%i.hdf5\" % i)\n",
    "\n",
    "    score = cnn_.evaluate(X_test_shaped, y_test_shaped, verbose=0)\n",
    "    test_loss.append(score[0])\n",
    "    test_accs.append(score[1])\n",
    "\n",
    "    print('Running final test with model %i: %0.4f loss / %0.4f acc' % (i, score[0], score[1]))\n",
    "\n",
    "print('\\nAverage loss / accuracy on testset: %0.4f loss / %0.5f acc' % (np.mean(test_loss), np.mean(test_accs)))\n",
    "print('Standard deviation: (+-%0.4f) loss / (+-%0.4f) acc' % (np.std(test_loss), np.std(test_accs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8df4c3-e773-4f86-9c08-cc00b73fd835",
   "metadata": {},
   "source": [
    "## Plotting accuracy and loss for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440c844-970a-4ab7-a530-8e59516166ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_acc_loss('training', histories, 'accuracy', 'loss')\n",
    "utils.plot_acc_loss('validation', histories, 'val_accuracy', 'val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e5dfa-a07a-4c0c-b7b8-6fbe2f171e78",
   "metadata": {},
   "source": [
    "## Evaluation for one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44bbc6-2503-434e-a525-37ad774e4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = 0 # you can choose one of the different models trained above\n",
    "model = models.create_resnet50(input_shape = (img_height, img_width, channels), classes = num_classes)\n",
    "model.load_weights(\"fashion_mnist_ResNet50-%i.hdf5\" % RUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e518c3-8864-452e-af46-8a0b399149f1",
   "metadata": {},
   "source": [
    "## Plotting accuracy and loss for one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bcfa7e-056f-455a-957c-6f26192fe34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_train_val('Model %i' % RUN, histories[RUN])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2904fc-4b85-44a8-af6d-41f067687b84",
   "metadata": {},
   "source": [
    "## Displaying results of random predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5f77b-4a97-4fc3-806f-41e4e98232c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_sample_predictions(list(fashion_classes.values()), model, X_test_shaped, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054cea8-efaa-4d03-a33a-d7e692bc10e4",
   "metadata": {},
   "source": [
    "## Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f23e30-885a-47d8-9f6f-06d676d8b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_shaped, verbose=0)\n",
    "classes = np.argmax(predictions,axis=1)\n",
    "utils.plot_confusion_matrix(confusion_matrix(y_test, classes), list(fashion_classes.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71858c47-d909-49c4-a39b-e707956094dd",
   "metadata": {},
   "source": [
    "## Report of f1, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae92ce-2694-468c-88fe-06194bd8cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
